![[Pasted image 20231001225538.png]]

(bias는 추가하지 않을 수 있음)

Cost function 뒤에 $$\frac{1}{m}\frac{\lambda}{2} \sum_{j=1}^{n_x}w_j^2$$
를 추가하는 것.


여기서 $\lambda$ 는 정규화 강도를 조절하는 하이퍼파라미터.
모델의 가중치가 얼마나 크게 패널티를 받아야 하는지를 결정함.
-> 가중치 패널티 & 가중치 스케일링 & 과적합 방지

L2 정규화 : [[L2 노름]]의 최소화!!!
가중치 값을 작게 만들지만 0으로 만들지는 않음, 스케일링 효과
-> silver bullet 은 아님! 다른 테크닉과 conjunction 해야 함!

![[Pasted image 20231001235543.png]]
이 값을 줄이는게 L2 정규화의 효과
이 값이 뭔데? [[프로베니우스 노름]]


[[최대 가능도 추정법(MLE)]]
![[Pasted image 20231002000004.png]]
PDF = probability Density Function, [[확률밀도함수]]

맨 밑 Log likelihood를 최대화 시켜야 한다!! (MLE)