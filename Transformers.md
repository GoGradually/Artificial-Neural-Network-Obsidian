 시작 심볼 \<sos>를 입력으로 받아 종료 심볼 \<eos>가 나올 때까지 연산

### 포지셔널 인코딩
단어를 순차적으로 받지 않으므로 입력에 순서를 직접 지정해서 추가로 줘야할 필요가 생김
-> 임베딩 벡터에 위치 정보까지 포함 = 포지셔널 인코딩![[Pasted image 20231211012748.png]]![[Pasted image 20231211012805.png]]
포지셔녈 임베딩 대신
포지셔널 인코딩 사용한다. -> 문장의 길이를 추정할 수 있게된다...?
근데 GPT나 BERT는 포지셔널 임베딩 사용한다?? 너무 많은 데이터가 있어서