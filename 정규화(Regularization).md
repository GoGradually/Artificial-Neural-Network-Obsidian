[[정규화를 하는 이유]]

[[신경망에서의 정규화]]

정규화(Regularization)는 머신 러닝과 딥 러닝에서 사용되는 중요한 개념 중 하나로, 모델의 복잡성을 제어하고 과적합(Overfitting)을 방지하기 위해 적용됩니다. 정규화는 모델의 학습 과정에서 추가적인 제약 조건을 부여하여 모델의 가중치(weight)나 파라미터(parameter)를 제한합니다. 이를 통해 모델이 훈련 데이터에 너무 맞추지 않고 일반화할 수 있도록 도와줍니다.

가장 널리 사용되는 정규화 기법에는 다음과 같은 것들이 있습니다:

1. **[[L1 정규화 ]](L1 Regularization 또는 Lasso):**
    - L1 정규화는 모델의 손실 함수에 가중치의 L1 [[노름]](norm)을 추가합니다. 이는 가중치의 절댓값 합을 최소화하는 방식으로 작동합니다.
    - L1 정규화는 특성 선택(feature selection)의 역할을 할 수 있으며, 일부 가중치를 0으로 만들어 특성을 제거하는 효과를 가집니다.
2. **[[L2 정규화]] (L2 Regularization 또는 Ridge):**
    - L2 정규화는 모델의 손실 함수에 가중치의 L2 [[노름]]을 추가합니다. 이는 가중치의 제곱합을 최소화하는 방식으로 작동합니다.
    - L2 정규화는 가중치 값을 작게 만들어 과적합을 줄이는 효과가 있으며, 모든 가중치가 조금씩 줄어들게 됩니다.
3. **[[드롭아웃]] (Dropout):**
    - 드롭아웃은 신경망의 학습 중에 무작위로 일부 뉴런을 비활성화하는 기법입니다. 즉, 학습 과정에서 일부 뉴런을 랜덤하게 '드롭아웃'시킵니다.
    - 이로써 모델은 여러 가지 부분집합을 학습하게 되어 과적합을 방지하고 일반화 능력을 향상시킵니다.
4. **[[Early Stopping]]:**
    - 조기 종료(Early Stopping)는 학습을 일찍 종료하여 과적합을 방지하는 방법입니다. 검증 데이터의 성능이 향상되지 않을 때 학습을 종료합니다.
5. **기타 정규화 기법:**
    
    - 기타 정규화 기법으로는 [[배치 정규화(Batch Normalization)]], [[Data augmentation]], 드롭콘넥트(DropConnect), 엘래스틱 넷(Elastic Net) 등이 있습니다.

정규화를 사용하면 모델이 훈련 데이터에만 지나치게 적합하지 않고 새로운 데이터에 대한 일반화 능력을 향상시킬 수 있습니다. 정규화 기법을 어떻게 적용할지는 모델과 데이터에 따라 다를 수 있으며, 하이퍼파라미터 튜닝을 통해 최적의 정규화 설정을 찾는 것이 중요합니다.

[[Normalizing input]]