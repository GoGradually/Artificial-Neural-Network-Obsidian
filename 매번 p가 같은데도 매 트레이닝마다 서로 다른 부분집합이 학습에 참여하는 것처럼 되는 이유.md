기댓값 덕분에 매번 다르게 가정됨?
역전파 시 특정 뉴런의 힘이 약해짐으로 인해서 오히려 잘못된 결과가 나올 수도 있는거 아닌가
결국은 수렴한다?
그냥 단순히 대충 모든 뉴런들이 출력값/2 의 값을 가지게 되는 것 아닌가
결과는 단순히 출력값/2지만 그 과정에 서로 다른 부분집합이 학습에 참여하는 효과가 생겼다는 것을 증명한 것인가?
-> 모델의 유닛을 절반만 쓰는 트레이닝 과정이 만들어짐
-> 각 부분집합이 달라진 것을 가정할 수 있게 된다