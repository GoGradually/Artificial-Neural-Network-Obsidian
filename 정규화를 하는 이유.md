![[Pasted image 20231001225041.png]]

![[Pasted image 20231002005712.png]]

정규화 항을 추가함으로써 벡터의 크기([[노름]])을 줄여서
가중치의 분산을 조절한다 -> [[역전파(Backpropagation)]] 시 미분값이 변한다


chat GPT answer
	정규화는 머신 러닝과 딥 러닝 모델에서 사용되는 중요한 기법 중 하나이며 다음과 같은 몇 가지 이유로 사용됩니다:
	1. **과적합 방지:** 모델이 학습 데이터에 너무 맞춰져 새로운 데이터에 일반화하지 못하는 [[과적합(Overfitting)]] 문제를 방지합니다. 과적합은 모델이 학습 데이터의 잡음(noise)까지 학습하여 성능이 떨어지는 결과를 초래할 수 있습니다. 정규화는 모델의 복잡성을 제한하고 일반화 능력을 향상시킵니다.
	2. **안정성 향상:** 모델의 가중치(weight) 값들이 큰 값을 가지지 않도록 제한함으로써, 모델이 훈련 데이터에 민감하게 반응하는 것을 막습니다. 이는 학습 과정에서 가중치의 큰 변화를 줄여 안정적인 학습을 돕습니다.
	3. **효율적인 학습:** 정규화를 사용하면 모델이 수렴(convergence)하는 속도가 향상될 수 있습니다. 가중치가 작아지면 그레디언트(Gradient) 업데이트가 빨라져 학습이 빨리 수렴될 수 있습니다.
	4. **다중 공선성 제거:** 다중 공선성(multicollinearity)은 특성들 간에 강한 상관관계가 있을 때 발생하는 문제입니다. 정규화를 사용하면 특성들 간의 상관관계를 줄이고 모델을 안정화할 수 있습니다.
	5. **특성 선택:** L1 정규화(L1 Regularization 또는 Lasso)를 사용하면 중요한 특성을 선택하고 불필요한 특성을 제거하는 효과를 가집니다. 이는 모델의 설명력을 향상시키고 더 간결한 모델을 만듭니다.




tanh 함수는 얼마나 많은 유닛을 추가를 하든 미분값이 1이 된다
마치 선형 함수처럼 된다
모든 탄젠트가 선형 함수처럼 된다
얼마나 많은 레이어를 추가하던 1층 선형레이어 처럼 된다
로지스틱 회귀처럼 된다
그래서 노름을 줄인다!!!!!