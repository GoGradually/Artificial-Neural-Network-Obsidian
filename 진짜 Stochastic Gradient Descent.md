**Stochastic Gradient Descent (확률적 경사 하강법, SGD):**
    - 각 학습 데이터 포인트마다 경사를 계산하고 모델 파라미터를 업데이트합니다.
    - 데이터 포인트 하나씩 사용하므로 메모리 사용량이 낮고 연산 비용이 낮습니다. -> 기댓값 사용
    - 노이즈가 있는 경사 업데이트로 수렴이 불안정할 수 있지만 수렴이 빠르게 일어날 수 있습니다.
    - 확률적 요소 때문에 경사 하강법 중 가장 불안정한 방법이며, 최소값 주변을 탐색할 수 있습니다.
![[Pasted image 20230929223600.png]]
![[Pasted image 20230929223743.png]]