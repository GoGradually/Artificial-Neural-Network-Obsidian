하이퍼파라미터(Hyperparameter)는 기계 학습 및 딥러닝 모델을 훈련할 때 조정해야 하는 모델 설정 값입니다. 이러한 설정 값은 모델의 구조와 학습 과정을 제어하며, 데이터에 따라 최적의 하이퍼파라미터 값을 찾아야 합니다. 주요 하이퍼파라미터에는 다음과 같은 것들이 있습니다:

1. **학습률 ([[Learning Rate]])**: 경사 하강법과 같은 최적화 알고리즘에서 사용되는 하이퍼파라미터로, 각 학습 스텝에서 파라미터를 업데이트할 때 그래디언트에 곱해지는 스케일 파라미터입니다. 적절한 학습률을 선택하는 것이 모델 학습의 핵심입니다.
    
2. **[[에포크(epoch)]])**: 모델을 전체 학습 데이터로 반복적으로 훈련하는 횟수를 결정합니다. 너무 적은 에포크로는 모델이 학습하지 못하고, 너무 많은 에포크로는 과적합(Overfitting)의 위험이 있으므로 조절해야 합니다.
    
3. **미니 배치 크기 ([[Batch Size]])**: 미니 배치 경사 하강법을 사용하는 경우, 한 번에 처리할 데이터 샘플의 수를 결정합니다. 배치 크기는 메모리 사용량과 학습 속도에 영향을 미치며, 적절한 값을 찾아야 합니다.
    
4. **은닉층 수와 뉴런 수**: 딥러닝 모델의 구조를 결정하는 하이퍼파라미터로, 은닉층의 수와 각 층의 뉴런 수를 조절합니다. 모델의 복잡성과 용량(capacity)을 결정하므로 조절이 필요합니다.
    
5. **활성화 함수 ([[Activation Function]])**: 각 뉴런에서 사용되는 활성화 함수를 선택하는 것도 하이퍼파라미터 중 하나입니다. 시그모이드, 렐루, 탄젠트 등 다양한 활성화 함수가 있으며, 문제에 따라 선택합니다.
    
6. **가중치 초기화 (Weight Initialization)**: 모델의 가중치를 초기화하는 방법을 결정하는 하이퍼파라미터입니다. 가중치 초기화 방법은 모델의 수렴 속도와 학습 품질에 영향을 줄 수 있습니다.
    
7. **정규화 (Regularization)**: 모델의 과적합을 제어하기 위해 사용되는 하이퍼파라미터로, L1 정규화, L2 정규화와 같은 규제 항의 강도를 결정합니다.
    
8. **[[드롭아웃]] (Dropout)**: 과적합을 줄이기 위해 사용되는 드롭아웃 비율을 결정하는 하이퍼파라미터입니다.
    
9. **컨볼루션 및 풀링 크기**: 컨볼루션 신경망(CNN) 모델의 컨볼루션 필터 크기와 풀링 크기를 조절하는 하이퍼파라미터입니다.
    

하이퍼파라미터 튜닝은 모델의 성능을 최적화하는 과정 중요한 부분이며, 주로 교차 검증(Cross-validation) 및 그리드 서치(Grid Search)와 같은 기법을 사용하여 최적의 하이퍼파라미터 값을 찾습니다. 하이퍼파라미터 튜닝은 모델의 일반화 능력을 향상시키고 고성능 모델을 만드는 데 중요한 단계입니다.