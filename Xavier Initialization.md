
![[Pasted image 20231002115856.png]]
[['~'의 의미]]
$n_{in}$ = label의 input feature의 수
$n_{out}$ = label의 output feature 의 수

Chat GPT answer of Xavier initialization
	Xavier 초기화(Xavier Initialization)는 딥 뉴럴 네트워크에서 가중치(weight)를 초기화하는 방법 중 하나로, 효율적인 학습을 위해 개발된 초기화 방법 중 하나입니다. 이 초기화 방법은 특히 S자 형태의 활성화 함수(예: 시그모이드 함수 또는 하이퍼볼릭 탄젠트 함수)와 함께 사용될 때 잘 동작하며, 그 이유는 활성화 함수의 특성과 관련이 있습니다.
	Xavier 초기화의 주요 아이디어는 가중치를 적절하게 초기화하여 그래디언트 소실(vanishing gradient) 또는 폭주(exploding gradient) 문제를 줄이는 것입니다. 이를 위해 Xavier 초기화는 다음과 같은 방식으로 가중치를 초기화합니다:
	1. 가중치 초기화: 가중치 행렬을 초기화할 때, 평균이 0이고 분산(또는 표준편차)가 1/n을 사용하여 초기화합니다.
	2. 수식으로 표현하면, 특정 가중치 행렬 W의 초기화는 다음과 같습니다.
	    W = random values with mean=0 and variance=1/n
	    여기서 n은 이전 레이어의 입력 뉴런 수입니다.
	Xavier 초기화는 Glorot 초기화라고도 불리며, 이 초기화 방법은 활성화 함수의 입력 범위와 출력 범위를 고려하여 가중치를 초기화합니다. 이러한 초기화 방법은 가중치의 분산을 적절하게 조절하여 그래디언트의 전파를 안정화시키는 데 도움을 줍니다.
	Xavier 초기화는 일반적으로 S자 형태의 활성화 함수와 함께 사용되며, 이러한 활성화 함수를 사용하는 네트워크에서 학습 성능과 수렴 속도를 향상시킬 수 있습니다.