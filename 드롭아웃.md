매 트레이닝마다 뉴런을 랜덤하게 비활성화 하는 방식의 정규화
과적합을 막는다? 어떻게?
1. 앙상블 효과 
	- 매 학습마다 서로 다른 부분집합이 학습에 참여
2. 복잡한 상호작용 방지
	- 특정 뉴런이 훈련 데이터에 지나치게 의존하는 상황 방지
3. 노이즈 추가
	- 노이즈를 추가하는 효과가 생김
4. 가중치 공유 제한
	- 모델이 가중치에 과도하게 의존하는 상황 방지

![[Pasted image 20231002112437.png]]

실제 적용 방식 
- 트레이닝 시 : 0부터 1 사이의 난수를 생성, 해당 난수보다 크면 살리고 아니면 제거한다.
- 테스팅 시 :  (1-p)를 곱함으로써 뉴런을 활성화시키는 확률을 곱한다

여기서 기댓값의 개념 적용
$E[z] = (1 - p)z'$
-> 기댓값으로 실제 테스팅 환경에서 진짜 제대로 된 값 나오는 경우를 더함

[[매번 p가 같은데도 매 트레이닝마다 서로 다른 부분집합이 학습에 참여하는 것처럼 되는 이유]]
일단 유닛을 살려는 두는게 역전파 시 그래디언트가 효과적으로 전달되게 할 수 있다

파이토치에서는 실제로 (1-p)가 아닌 $\frac{1}{1-p}$ 를 곱한다