1. 아키텍처 깊이:
    
    - AlexNet: AlexNet은 2012년 ILSVRC에서 소개되었으며, 상당히 깊은 네트워크로 시작했습니다. 그러나 현재의 딥 러닝 모델과 비교하면 상대적으로 얕은 아키텍처입니다.
    - VGGNet: VGGNet은 2014년 ILSVRC에서 소개되었으며, 상당히 깊은 아키텍처로 각각 16개 또는 19개의 레이어를 포함하는 두 가지 버전이 있습니다. 이로써 VGGNet은 AlexNet보다 훨씬 깊은 네트워크로 분류됩니다.
2. 컨볼루션 필터 크기:
    
    - AlexNet: AlexNet은 주로 11x11 크기의 컨볼루션 필터를 사용했습니다. 이 큰 필터 크기는 AlexNet의 초기 레이어에서 공간적인 정보를 캡처하는 데 도움을 주었습니다.
    - VGGNet: VGGNet은 3x3 크기의 작은 컨볼루션 필터를 사용했습니다. 이 작은 필터 크기는 신경망을 깊게 설계할 수 있게 했으며, 다양한 크기의 이미지에서 효과적인 특성 추출을 가능케 했습니다.
3. 구조:
    
    - AlexNet: AlexNet은 5개의 컨볼루션 레이어와 3개의 완전 연결 레이어로 구성되어 있습니다. 중간에 폴링 레이어가 있으며, Local Response Normalization (LRN) 레이어가 사용되었습니다.
    - VGGNet: VGGNet은 VGG16 및 VGG19와 같이 각각 16개 또는 19개의 컨볼루션 레이어, 폴링 레이어, 그리고 완전 연결 레이어로 구성되어 있습니다. LRN 대신 Batch Normalization을 사용하였습니다.
4. 파라미터 수:
    
    - AlexNet: AlexNet의 파라미터 수는 60M 개 정도로 비교적 작은 모델입니다.
    - VGGNet: VGGNet은 138M (VGG16) 또는 144M (VGG19) 개의 파라미터를 가지며, 상당히 많은 파라미터로 구성되어 있습니다.