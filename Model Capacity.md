모델 용량(Model Capacity)은 모델이 데이터를 얼마나 복잡하게 모사하고 저장할 수 있는지를 나타내는 개념입니다. 모델의 용량이 높을수록 모델은 더 복잡한 함수를 표현할 수 있으며, 학습 데이터에 더 정확하게 적합할 수 있습니다. 모델의 용량은 모델의 표현력(representational power)을 나타냅니다.

모델의 용량이 낮다면, 모델은 간단한 함수만을 표현할 수 있으며, 데이터의 복잡한 패턴이나 관계를 잘 파악하기 어렵습니다. 이 경우에는 고편향(Bias) 문제가 발생할 수 있습니다. 모델이 학습 데이터에 대한 오차가 크고, 훈련 데이터와 테스트 데이터 모두에서 성능이 낮을 수 있습니다.

모델의 용량이 높다면, 모델은 학습 데이터에 더 정확하게 맞출 수 있으며, 데이터의 복잡한 패턴을 잘 포착할 수 있습니다. 그러나 이 경우에는 [[과적합(Overfitting)]]문제가 발생할 수 있습니다. 모델이 학습 데이터에 지나치게 적합하여 새로운 데이터에 대한 일반화 능력이 떨어질 수 있습니다.

따라서 모델의 용량은 적절하게 조절되어야 합니다. 이를 위해 다음과 같은 접근 방법들을 사용할 수 있습니다:

1. **모델 선택:** 모델의 복잡성을 조절하기 위해 적절한 모델 아키텍처를 선택합니다. 모델의 층(layer) 수, 뉴런 수, 합성곱 필터의 크기 등을 조절할 수 있습니다.
    
2. **[[정규화(Regularization)]]** : 정규화 기법을 사용하여 모델의 복잡성을 제한합니다. L1 또는 L2 정규화, 드롭아웃과 같은 기법을 적용합니다.
    
3. **[[Hyperparameter]] 튜닝:** 학습률, 배치 크기, 에포크 수 등과 같은 하이퍼파라미터를 조정하여 모델의 학습을 조절합니다.
    

적절한 모델 용량을 선택하면 모델이 학습 데이터를 잘 파악하고 일반화 능력을 갖출 수 있습니다. 모델 용량은 일종의 트레이드오프 관계를 가지며, 최적의 모델 용량을 찾는 것은 머신 러닝 및 딥 러닝 모델의 중요한 과제 중 하나입니다.