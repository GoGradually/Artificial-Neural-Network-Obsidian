같이보기 : [[과적합(Overfitting)]]
우리의 목표 : 둘 다 낮추기!!!!!
둘 다 줄이는 법...
둘의 trade-off 관계 이해하기

Bias와 Variance는 모델의 성능과 관련된 두 가지 중요한 개념으로, 모델의 복잡성과 관련이 있습니다. 이 두 가지 요소는 모델의 일반화(generalization) 능력을 이해하고 평가하는 데 중요합니다.

1. **Bias (편향):**
    
    - Bias는 모델이 주어진 데이터에 대한 잘못된 가정 또는 간단한 모델로 인해 발생하는 오차를 나타냅니다.
    - 고편향 모델은 데이터의 패턴을 잘 파악하지 못하고, 학습 데이터에 대한 오차가 큽니다. 이는 모델이 너무 단순하다는 의미입니다.
    - 예측 오차가 훈련 데이터에서도 크고 테스트 데이터에서도 큰 경우, 모델은 고편향을 가진 것으로 간주됩니다.
1. **Variance (분산):**
    
    - Variance는 모델이 학습 데이터의 작은 변동에 민감하게 반응하여 발생하는 오차의 정도를 나타냅니다.
    - 고분산 모델은 학습 데이터에 [[과적합(Overfitting)]]되기 쉽고, 테스트 데이터에서의 성능이 훈련 데이터보다 낮을 수 있습니다.
    - 모델이 학습 데이터에 지나치게 맞추려고 할 때 발생하며, 이는 모델이 너무 복잡하다는 의미입니다.

Bias와 Variance의 관계는 다음과 같습니다:

- **Trade-off 관계:** Bias와 Variance는 일반적으로 상충 관계에 있습니다. 모델의 복잡성을 증가시키면 Variance가 증가하고 Bias는 감소합니다. 반대로 모델의 복잡성을 감소시키면 Bias가 증가하고 Variance는 감소합니다.
    
- **모델 선택:** 모델을 선택할 때는 Bias와 Variance 사이의 적절한 균형을 찾아야 합니다. 너무 단순한 모델은 고편향을 가지며 데이터의 복잡한 패턴을 파악하지 못할 수 있습니다. 너무 복잡한 모델은 고분산을 가지며 학습 데이터에 과적합될 수 있습니다.
    
- **Cross-Validation:** 모델의 성능을 평가할 때, 교차 검증(Cross-Validation)을 사용하여 Bias와 Variance를 고려하는 것이 중요합니다. 교차 검증을 통해 모델이 훈련 데이터와 테스트 데이터 모두에서 일반적으로 잘 수행하는지 확인할 수 있습니다.
    

좋은 모델은 Bias와 Variance 사이의 균형을 유지하며, 훈련 데이터와 테스트 데이터 모두에서 좋은 성능을 보이는 모델입니다.